{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Bag of Binary Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "random.seed(123123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dbow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Images\n",
    "images_path = glob.glob('./images/*.png')\n",
    "images = []\n",
    "for image_path in images_path:\n",
    "    images.append(cv2.imread(image_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Vocabulary\n",
    "n_clusters = 10\n",
    "depth = 2\n",
    "vocabulary = dbow.Vocabulary(images, n_clusters, depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Image 0 and Image 0 = 1.0\n",
      "Similarity between Image 0 and Image 1 = 0.7229233184318078\n",
      "Similarity between Image 0 and Image 2 = 0.6406113156187837\n",
      "Similarity between Image 0 and Image 3 = 0.5847393061959807\n",
      "\n",
      "\n",
      "Similarity between Image 1 and Image 0 = 0.7229233184318078\n",
      "Similarity between Image 1 and Image 1 = 1.0\n",
      "Similarity between Image 1 and Image 2 = 0.48801849310811596\n",
      "Similarity between Image 1 and Image 3 = 0.4678571555415687\n",
      "\n",
      "\n",
      "Similarity between Image 2 and Image 0 = 0.6406113156187837\n",
      "Similarity between Image 2 and Image 1 = 0.48801849310811596\n",
      "Similarity between Image 2 and Image 2 = 1.0\n",
      "Similarity between Image 2 and Image 3 = 0.578817843610727\n",
      "\n",
      "\n",
      "Similarity between Image 3 and Image 0 = 0.5847393061959807\n",
      "Similarity between Image 3 and Image 1 = 0.4678571555415687\n",
      "Similarity between Image 3 and Image 2 = 0.578817843610727\n",
      "Similarity between Image 3 and Image 3 = 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert images to Bag of Binary Words and calculate scores between them\n",
    "bows = []\n",
    "for image in images:\n",
    "    kps, descs = orb.detectAndCompute(image, None)\n",
    "    descs = [dbow.ORB.from_cv_descriptor(desc) for desc in descs]\n",
    "    bows.append(vocabulary.descs_to_bow(descs))\n",
    "\n",
    "for i in range(len(bows)):\n",
    "    for j in range(len(bows)):\n",
    "        print(f'Similarity between Image {i} and Image {j} = {bows[i].score(bows[j])}')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a database\n",
    "db = dbow.Database(vocabulary)\n",
    "for image in images:\n",
    "    kps, descs = orb.detectAndCompute(image, None)\n",
    "    descs = [dbow.ORB.from_cv_descriptor(desc) for desc in descs]\n",
    "    db.add(descs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Query the database\n",
    "for image in images:\n",
    "    kps, descs = orb.detectAndCompute(image, None)\n",
    "    descs = [dbow.ORB.from_cv_descriptor(desc) for desc in descs]\n",
    "    scores = db.query(descs)\n",
    "    match_bow = db[np.argmax(scores)]\n",
    "    match_desc = db.descriptors[np.argmax(scores)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving and Loading the vocabulary\n",
    "vocabulary.save('vocabulary.pickle')\n",
    "loaded_vocabulary = vocabulary.load('vocabulary.pickle')\n",
    "for image in images:\n",
    "    kps, descs = orb.detectAndCompute(image, None)\n",
    "    descs = [dbow.ORB.from_cv_descriptor(desc) for desc in descs]\n",
    "    loaded_vocabulary.descs_to_bow(descs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'dbow.dbow.Vocabulary'>: it's not the same object as dbow.dbow.Vocabulary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-00be0d937323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saving and Loading the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloaded_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/pydbow/dbow/dbow.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'dbow.dbow.Vocabulary'>: it's not the same object as dbow.dbow.Vocabulary"
     ]
    }
   ],
   "source": [
    "# Saving and Loading the database\n",
    "db.save('database.pickle')\n",
    "loaded_db = db.load('database.pickle')\n",
    "for image in images:\n",
    "    kps, descs = orb.detectAndCompute(image, None)\n",
    "    descs = [dbow.ORB.from_cv_descriptor(desc) for desc in descs]\n",
    "    scores = loaded_db.query(descs)\n",
    "    print(loaded_db[np.argmax(scores)], np.argmax(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
